{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# üéØ Logo Classification Training - Day 5 Enhanced Pipeline\n",
        "\n",
        "**Project**: SVG-AI Converter - Neural Network Logo Classification  \n",
        "**Goal**: Achieve >85% accuracy using EfficientNet-B0 with enhanced optimizations  \n",
        "**Hardware**: GPU-accelerated training in Google Colab  \n",
        "\n",
        "## üìã Day 5 Optimizations Included:\n",
        "- ‚úÖ **Optimized Hyperparameters** (LR: 0.0005, batch size: 16, dropout: 0.4)\n",
        "- ‚úÖ **Logo-Specific Data Augmentation** (preserves brand characteristics)\n",
        "- ‚úÖ **Weighted Focal Loss** (handles class imbalance + hard examples)\n",
        "- ‚úÖ **Progressive Unfreezing** (4-stage transfer learning strategy)\n",
        "- ‚úÖ **Enhanced Classifier Architecture** (256-dim hidden layer)\n",
        "- ‚úÖ **Gradient Clipping** (prevents exploding gradients)\n",
        "- ‚úÖ **Advanced Monitoring** (real-time plots + metrics)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## üöÄ 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No GPU detected - training will be slower\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import json\n",
        "import time\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "from collections import defaultdict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üîß Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_section"
      },
      "source": [
        "## üìÇ 2. Data Preparation\n",
        "\n",
        "### Upload Your Logo Dataset\n",
        "\n",
        "**Option 1**: Upload a ZIP file containing all your logo images  \n",
        "**Option 2**: Upload individual images to `/content/raw_logos/`  \n",
        "\n",
        "**Expected**: 600-800 logo images for 4 classes:\n",
        "- **Simple**: Geometric shapes, minimal design\n",
        "- **Text**: Typography-focused, wordmarks  \n",
        "- **Gradient**: Color gradients, modern styles\n",
        "- **Complex**: Detailed illustrations, multiple elements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload_data"
      },
      "outputs": [],
      "source": [
        "# Create data directories\n",
        "os.makedirs('/content/raw_logos', exist_ok=True)\n",
        "os.makedirs('/content/dataset', exist_ok=True)\n",
        "\n",
        "print(\"üìÅ Data directories created:\")\n",
        "print(\"   /content/raw_logos/     ‚Üê Upload your logo images here\")\n",
        "print(\"   /content/dataset/       ‚Üê Organized dataset will be created here\")\n",
        "print(\"\\nüîÑ Please upload your logo images to /content/raw_logos/\")\n",
        "print(\"   (Use the file browser on the left or drag & drop)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dataset_class"
      },
      "outputs": [],
      "source": [
        "class LogoDataset(Dataset):\n",
        "    \"\"\"Enhanced PyTorch Dataset for logo classification with GPU optimization\"\"\"\n",
        "    \n",
        "    def __init__(self, data_dir: str, transform: Optional[callable] = None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.classes = ['simple', 'text', 'gradient', 'complex']\n",
        "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
        "        self.samples = self._load_samples()\n",
        "        \n",
        "        print(f\"üìä Dataset loaded from {data_dir}\")\n",
        "        print(f\"   Classes: {self.classes}\")\n",
        "        print(f\"   Total samples: {len(self.samples)}\")\n",
        "        self._log_class_distribution()\n",
        "    \n",
        "    def _load_samples(self) -> List[Tuple[str, int]]:\n",
        "        \"\"\"Load all image samples with their labels\"\"\"\n",
        "        samples = []\n",
        "        \n",
        "        for class_name in self.classes:\n",
        "            class_dir = os.path.join(self.data_dir, class_name)\n",
        "            \n",
        "            if not os.path.exists(class_dir):\n",
        "                print(f\"‚ö†Ô∏è  Class directory not found: {class_dir}\")\n",
        "                continue\n",
        "            \n",
        "            # Get all image files\n",
        "            for img_file in os.listdir(class_dir):\n",
        "                if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    img_path = os.path.join(class_dir, img_file)\n",
        "                    label = self.class_to_idx[class_name]\n",
        "                    samples.append((img_path, label))\n",
        "        \n",
        "        return samples\n",
        "    \n",
        "    def _log_class_distribution(self):\n",
        "        \"\"\"Log the distribution of samples across classes\"\"\"\n",
        "        class_counts = defaultdict(int)\n",
        "        for _, label in self.samples:\n",
        "            class_name = self.classes[label]\n",
        "            class_counts[class_name] += 1\n",
        "        \n",
        "        print(\"   Class distribution:\")\n",
        "        for class_name, count in class_counts.items():\n",
        "            print(f\"     {class_name}: {count} samples\")\n",
        "    \n",
        "    def __len__(self) -> int:\n",
        "        return len(self.samples)\n",
        "    \n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
        "        if idx >= len(self.samples):\n",
        "            raise IndexError(f\"Index {idx} out of range\")\n",
        "        \n",
        "        img_path, label = self.samples[idx]\n",
        "        \n",
        "        try:\n",
        "            # Load image and convert to RGB\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            \n",
        "            # Apply transforms if provided\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            \n",
        "            return image, label\n",
        "        \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading image {img_path}: {e}\")\n",
        "            # Return a black image as fallback\n",
        "            if self.transform:\n",
        "                dummy_image = Image.new('RGB', (224, 224), color='black')\n",
        "                image = self.transform(dummy_image)\n",
        "            else:\n",
        "                image = torch.zeros(3, 224, 224)\n",
        "            \n",
        "            return image, label\n",
        "    \n",
        "    def get_class_weights(self) -> torch.Tensor:\n",
        "        \"\"\"Calculate class weights for handling imbalanced datasets\"\"\"\n",
        "        class_counts = torch.zeros(len(self.classes))\n",
        "        \n",
        "        for _, label in self.samples:\n",
        "            class_counts[label] += 1\n",
        "        \n",
        "        # Avoid division by zero\n",
        "        class_counts = torch.clamp(class_counts, min=1)\n",
        "        \n",
        "        # Calculate inverse frequency weights\n",
        "        total_samples = len(self.samples)\n",
        "        class_weights = total_samples / (len(self.classes) * class_counts)\n",
        "        \n",
        "        print(f\"‚öñÔ∏è  Class weights: {class_weights}\")\n",
        "        return class_weights\n",
        "\n",
        "print(\"‚úÖ LogoDataset class defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data_organizer"
      },
      "outputs": [],
      "source": [
        "def organize_dataset(raw_dir: str, output_dir: str, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
        "    \"\"\"\n",
        "    Organize raw logo images into train/val/test splits\n",
        "    \n",
        "    This function will analyze filenames and categorize images based on keywords:\n",
        "    - 'simple', 'geometric', 'basic' ‚Üí simple class\n",
        "    - 'text', 'word', 'typography' ‚Üí text class  \n",
        "    - 'gradient', 'color', 'modern' ‚Üí gradient class\n",
        "    - 'complex', 'detailed', 'illustration' ‚Üí complex class\n",
        "    \"\"\"\n",
        "    \n",
        "    if not os.path.exists(raw_dir):\n",
        "        print(f\"‚ùå Raw directory not found: {raw_dir}\")\n",
        "        return False\n",
        "    \n",
        "    # Check if we have images\n",
        "    image_files = [f for f in os.listdir(raw_dir) \n",
        "                   if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    \n",
        "    if len(image_files) == 0:\n",
        "        print(f\"‚ùå No image files found in {raw_dir}\")\n",
        "        print(\"   Please upload your logo images first\")\n",
        "        return False\n",
        "    \n",
        "    print(f\"üìÇ Found {len(image_files)} images to organize\")\n",
        "    \n",
        "    # Define classification keywords\n",
        "    classification_rules = {\n",
        "        'simple': ['simple', 'geometric', 'basic', 'minimal', 'circle', 'square', 'triangle'],\n",
        "        'text': ['text', 'word', 'typography', 'font', 'letter', 'google', 'ibm'],\n",
        "        'gradient': ['gradient', 'color', 'modern', 'instagram', 'colorful', 'rainbow'],\n",
        "        'complex': ['complex', 'detailed', 'illustration', 'starbucks', 'intricate', 'emblem']\n",
        "    }\n",
        "    \n",
        "    # Categorize images\n",
        "    categorized_images = {cls: [] for cls in classification_rules.keys()}\n",
        "    uncategorized = []\n",
        "    \n",
        "    for img_file in image_files:\n",
        "        filename_lower = img_file.lower()\n",
        "        categorized = False\n",
        "        \n",
        "        for class_name, keywords in classification_rules.items():\n",
        "            if any(keyword in filename_lower for keyword in keywords):\n",
        "                categorized_images[class_name].append(img_file)\n",
        "                categorized = True\n",
        "                break\n",
        "        \n",
        "        if not categorized:\n",
        "            uncategorized.append(img_file)\n",
        "    \n",
        "    # Handle uncategorized images\n",
        "    if uncategorized:\n",
        "        print(f\"‚ö†Ô∏è  {len(uncategorized)} images couldn't be auto-categorized:\")\n",
        "        for img in uncategorized[:5]:  # Show first 5\n",
        "            print(f\"     {img}\")\n",
        "        if len(uncategorized) > 5:\n",
        "            print(f\"     ... and {len(uncategorized)-5} more\")\n",
        "        \n",
        "        # Distribute uncategorized images evenly\n",
        "        print(\"üìä Distributing uncategorized images evenly across classes\")\n",
        "        class_names = list(classification_rules.keys())\n",
        "        for i, img in enumerate(uncategorized):\n",
        "            class_name = class_names[i % len(class_names)]\n",
        "            categorized_images[class_name].append(img)\n",
        "    \n",
        "    # Show categorization results\n",
        "    print(\"\\nüìã Categorization results:\")\n",
        "    for class_name, images in categorized_images.items():\n",
        "        print(f\"   {class_name}: {len(images)} images\")\n",
        "    \n",
        "    # Create output directory structure\n",
        "    splits = ['train', 'val', 'test']\n",
        "    ratios = [train_ratio, val_ratio, test_ratio]\n",
        "    \n",
        "    for split in splits:\n",
        "        for class_name in categorized_images.keys():\n",
        "            os.makedirs(os.path.join(output_dir, split, class_name), exist_ok=True)\n",
        "    \n",
        "    # Split and copy images\n",
        "    print(\"\\nüîÑ Creating train/val/test splits...\")\n",
        "    \n",
        "    for class_name, images in categorized_images.items():\n",
        "        if len(images) == 0:\n",
        "            continue\n",
        "        \n",
        "        # Shuffle images\n",
        "        np.random.shuffle(images)\n",
        "        \n",
        "        # Calculate split sizes\n",
        "        n_total = len(images)\n",
        "        n_train = int(n_total * train_ratio)\n",
        "        n_val = int(n_total * val_ratio)\n",
        "        n_test = n_total - n_train - n_val  # Remaining goes to test\n",
        "        \n",
        "        # Split the images\n",
        "        train_images = images[:n_train]\n",
        "        val_images = images[n_train:n_train + n_val]\n",
        "        test_images = images[n_train + n_val:]\n",
        "        \n",
        "        # Copy images to appropriate directories\n",
        "        for split, split_images in zip(['train', 'val', 'test'], \n",
        "                                       [train_images, val_images, test_images]):\n",
        "            for img_file in split_images:\n",
        "                src_path = os.path.join(raw_dir, img_file)\n",
        "                dst_path = os.path.join(output_dir, split, class_name, img_file)\n",
        "                shutil.copy2(src_path, dst_path)\n",
        "        \n",
        "        print(f\"   {class_name}: {n_train} train, {n_val} val, {n_test} test\")\n",
        "    \n",
        "    print(f\"\\n‚úÖ Dataset organized successfully in {output_dir}\")\n",
        "    return True\n",
        "\n",
        "print(\"‚úÖ Dataset organization function defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_organization"
      },
      "outputs": [],
      "source": [
        "# Run dataset organization\n",
        "print(\"üîß Organizing dataset...\")\n",
        "success = organize_dataset('/content/raw_logos', '/content/dataset')\n",
        "\n",
        "if success:\n",
        "    print(\"\\nüìä Final dataset structure:\")\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        split_dir = f'/content/dataset/{split}'\n",
        "        if os.path.exists(split_dir):\n",
        "            total_images = sum(len([f for f in os.listdir(os.path.join(split_dir, cls)) \n",
        "                                  if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
        "                             for cls in ['simple', 'text', 'gradient', 'complex']\n",
        "                             if os.path.exists(os.path.join(split_dir, cls)))\n",
        "            print(f\"   {split}: {total_images} images\")\nelse:\n",
        "    print(\"‚ùå Dataset organization failed\")\n",
        "    print(\"   Please upload your logo images to /content/raw_logos/ first\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "transforms_section"
      },
      "source": [
        "## üé® 3. Enhanced Data Transforms\n",
        "\n",
        "### Logo-Specific Augmentation Strategy\n",
        "Designed to preserve brand characteristics while providing variation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "transforms"
      },
      "outputs": [],
      "source": [
        "class LogoSpecificAugmentation:\n",
        "    \"\"\"Logo-specific data augmentation that preserves brand characteristics\"\"\"\n",
        "    \n",
        "    def __init__(self, \n",
        "                 rotation_degrees=15,\n",
        "                 brightness_factor=0.3,\n",
        "                 contrast_factor=0.3,\n",
        "                 saturation_factor=0.2,\n",
        "                 horizontal_flip_prob=0.3,\n",
        "                 grayscale_prob=0.1):\n",
        "        \n",
        "        self.rotation_degrees = rotation_degrees\n",
        "        self.brightness_factor = brightness_factor\n",
        "        self.contrast_factor = contrast_factor\n",
        "        self.saturation_factor = saturation_factor\n",
        "        self.horizontal_flip_prob = horizontal_flip_prob\n",
        "        self.grayscale_prob = grayscale_prob\n",
        "    \n",
        "    def get_train_transforms(self):\n",
        "        \"\"\"Get training transforms with logo-specific augmentation\"\"\"\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.RandomResizedCrop(224, scale=(0.8, 1.0), ratio=(0.8, 1.2)),\n",
        "            transforms.RandomHorizontalFlip(p=self.horizontal_flip_prob),\n",
        "            transforms.RandomRotation(degrees=self.rotation_degrees),\n",
        "            transforms.ColorJitter(\n",
        "                brightness=self.brightness_factor,\n",
        "                contrast=self.contrast_factor,\n",
        "                saturation=self.saturation_factor\n",
        "            ),\n",
        "            transforms.RandomGrayscale(p=self.grayscale_prob),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                               std=[0.229, 0.224, 0.225])  # ImageNet normalization\n",
        "        ])\n",
        "    \n",
        "    def get_val_transforms(self):\n",
        "        \"\"\"Get validation transforms (no augmentation)\"\"\"\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                               std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "# Create augmentation instance\n",
        "augmentation = LogoSpecificAugmentation()\n",
        "train_transform = augmentation.get_train_transforms()\n",
        "val_transform = augmentation.get_val_transforms()\n",
        "\n",
        "print(\"‚úÖ Logo-specific data transforms created\")\n",
        "print(\"   üéØ Optimized for brand characteristic preservation\")\n",
        "print(\"   üìä Includes rotation, color jitter, flipping, and scaling\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_section"
      },
      "source": [
        "## üß† 4. Enhanced Model Architecture\n",
        "\n",
        "### EfficientNet-B0 with Optimized Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_classes"
      },
      "outputs": [],
      "source": [
        "class WeightedFocalLoss(nn.Module):\n",
        "    \"\"\"Focal loss with class weights for handling imbalanced data and hard examples\"\"\"\n",
        "    \n",
        "    def __init__(self, class_weights, alpha=0.25, gamma=2.0):\n",
        "        super(WeightedFocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.class_weights = class_weights\n",
        "    \n",
        "    def forward(self, inputs, targets):\n",
        "        # Move class weights to same device as inputs\n",
        "        if self.class_weights.device != inputs.device:\n",
        "            self.class_weights = self.class_weights.to(inputs.device)\n",
        "        \n",
        "        # Compute weighted cross entropy\n",
        "        ce_loss = nn.functional.cross_entropy(inputs, targets, \n",
        "                                            weight=self.class_weights, \n",
        "                                            reduction='none')\n",
        "        \n",
        "        # Compute focal loss\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
        "        \n",
        "        return focal_loss.mean()\n",
        "\n",
        "class TransferLearningStrategy:\n",
        "    \"\"\"Progressive unfreezing strategy for transfer learning\"\"\"\n",
        "    \n",
        "    def __init__(self, model, base_lr=0.0005):\n",
        "        self.model = model\n",
        "        self.base_lr = base_lr\n",
        "        self.current_stage = 0\n",
        "        \n",
        "        # Define training stages\n",
        "        self.stages = [\n",
        "            {'name': 'classifier_only', 'epochs': 15, 'lr_mult': 1.0},\n",
        "            {'name': 'last_2_blocks', 'epochs': 10, 'lr_mult': 0.5},\n",
        "            {'name': 'last_4_blocks', 'epochs': 10, 'lr_mult': 0.3},\n",
        "            {'name': 'full_finetuning', 'epochs': 15, 'lr_mult': 0.1}\n",
        "        ]\n",
        "    \n",
        "    def setup_stage(self, stage):\n",
        "        \"\"\"Setup model for specific training stage\"\"\"\n",
        "        self.current_stage = stage\n",
        "        \n",
        "        if stage == 0:\n",
        "            # Stage 0: Freeze all backbone, train classifier only\n",
        "            for param in self.model.features.parameters():\n",
        "                param.requires_grad = False\n",
        "            for param in self.model.classifier.parameters():\n",
        "                param.requires_grad = True\n",
        "                \n",
        "        elif stage == 1:\n",
        "            # Stage 1: Unfreeze last 2 blocks\n",
        "            for param in self.model.features.parameters():\n",
        "                param.requires_grad = False\n",
        "            for param in self.model.features[7:].parameters():  # Last 2 blocks\n",
        "                param.requires_grad = True\n",
        "            for param in self.model.classifier.parameters():\n",
        "                param.requires_grad = True\n",
        "                \n",
        "        elif stage == 2:\n",
        "            # Stage 2: Unfreeze last 4 blocks\n",
        "            for param in self.model.features.parameters():\n",
        "                param.requires_grad = False\n",
        "            for param in self.model.features[5:].parameters():  # Last 4 blocks\n",
        "                param.requires_grad = True\n",
        "            for param in self.model.classifier.parameters():\n",
        "                param.requires_grad = True\n",
        "                \n",
        "        elif stage == 3:\n",
        "            # Stage 3: Full fine-tuning\n",
        "            for param in self.model.parameters():\n",
        "                param.requires_grad = True\n",
        "        \n",
        "        stage_info = self.stages[stage]\n",
        "        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
        "        total_params = sum(p.numel() for p in self.model.parameters())\n",
        "        \n",
        "        print(f\"üîß Stage {stage}: {stage_info['name']}\")\n",
        "        print(f\"   Trainable parameters: {trainable_params:,} ({trainable_params/total_params:.1%})\")\n",
        "        \n",
        "        return stage_info\n",
        "    \n",
        "    def get_optimizer(self, stage):\n",
        "        \"\"\"Get optimizer with differential learning rates\"\"\"\n",
        "        stage_info = self.stages[stage]\n",
        "        lr = self.base_lr * stage_info['lr_mult']\n",
        "        \n",
        "        if stage == 0:\n",
        "            # Only classifier parameters\n",
        "            optimizer = optim.Adam(self.model.classifier.parameters(), lr=lr, weight_decay=1e-4)\n",
        "        else:\n",
        "            # Differential learning rates for backbone vs classifier\n",
        "            backbone_lr = lr * 0.1  # Lower LR for backbone\n",
        "            classifier_lr = lr      # Higher LR for classifier\n",
        "            \n",
        "            param_groups = [\n",
        "                {'params': [p for p in self.model.features.parameters() if p.requires_grad], 'lr': backbone_lr},\n",
        "                {'params': self.model.classifier.parameters(), 'lr': classifier_lr}\n",
        "            ]\n",
        "            optimizer = optim.Adam(param_groups, weight_decay=1e-4)\n",
        "        \n",
        "        print(f\"   Learning rate: {lr:.6f}\")\n",
        "        return optimizer\n",
        "\n",
        "def create_enhanced_model():\n",
        "    \"\"\"Create EfficientNet-B0 with enhanced classifier\"\"\"\n",
        "    print(\"üèóÔ∏è  Creating Enhanced EfficientNet-B0 model...\")\n",
        "    \n",
        "    # Load pre-trained EfficientNet-B0\n",
        "    model = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
        "    \n",
        "    # Enhanced classifier head (based on Day 5 Task 5.3.1 analysis)\n",
        "    num_features = model.classifier[1].in_features\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Dropout(0.4),           # Higher dropout for regularization\n",
        "        nn.Linear(num_features, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.3),           # Additional dropout layer\n",
        "        nn.Linear(256, 4)          # 4 logo classes\n",
        "    )\n",
        "    \n",
        "    model = model.to(device)\n",
        "    \n",
        "    # Count parameters\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "    print(f\"   ‚úÖ Model created with {total_params:,} total parameters\")\n",
        "    print(f\"   üéØ Enhanced classifier: {num_features} ‚Üí 256 ‚Üí 4\")\n",
        "    print(f\"   üìä Dropout rates: 0.4 ‚Üí 0.3 for better regularization\")\n",
        "    \n",
        "    return model\n",
        "\n",
        "print(\"‚úÖ Enhanced model classes defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training_section"
      },
      "source": [
        "## üöÄ 5. Enhanced Training Pipeline\n",
        "\n",
        "### GPU-Optimized Training with All Day 5 Enhancements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "training_functions"
      },
      "outputs": [],
      "source": [
        "def create_data_loaders(batch_size=16):\n",
        "    \"\"\"Create enhanced data loaders\"\"\"\n",
        "    print(f\"üìä Creating data loaders with batch_size={batch_size}\")\n",
        "    \n",
        "    # Create datasets\n",
        "    train_dataset = LogoDataset('/content/dataset/train', transform=train_transform)\n",
        "    val_dataset = LogoDataset('/content/dataset/val', transform=val_transform)\n",
        "    test_dataset = LogoDataset('/content/dataset/test', transform=val_transform)\n",
        "    \n",
        "    # Create data loaders with GPU optimization\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,  # GPU optimization\n",
        "        pin_memory=True  # Faster GPU transfer\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    \n",
        "    return train_loader, val_loader, test_loader, train_dataset\n",
        "\n",
        "def train_epoch(model, train_loader, optimizer, criterion, epoch, stage):\n",
        "    \"\"\"Train for one epoch with enhanced monitoring\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        # Zero gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        \n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Statistics\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        # Progress logging\n",
        "        if batch_idx % 5 == 0 and batch_idx > 0:\n",
        "            current_acc = 100. * correct / total\n",
        "            print(f\"   Batch {batch_idx:2d}/{len(train_loader):2d}: \"\n",
        "                  f\"Loss={loss.item():.4f}, Acc={current_acc:.1f}%\")\n",
        "    \n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    \n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def validate_epoch(model, val_loader, criterion):\n",
        "    \"\"\"Validate for one epoch with per-class metrics\"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    # Per-class metrics\n",
        "    class_correct = {i: 0 for i in range(4)}\n",
        "    class_total = {i: 0 for i in range(4)}\n",
        "    class_names = ['simple', 'text', 'gradient', 'complex']\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            \n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            # Per-class accuracy\n",
        "            for i in range(len(labels)):\n",
        "                label = labels[i].item()\n",
        "                class_total[label] += 1\n",
        "                if predicted[i].item() == label:\n",
        "                    class_correct[label] += 1\n",
        "    \n",
        "    epoch_loss = running_loss / len(val_loader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    \n",
        "    # Calculate per-class accuracy\n",
        "    per_class_acc = {}\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        if class_total[i] > 0:\n",
        "            per_class_acc[class_name] = class_correct[i] / class_total[i] * 100\n",
        "        else:\n",
        "            per_class_acc[class_name] = 0.0\n",
        "    \n",
        "    return epoch_loss, epoch_acc, per_class_acc\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch, train_acc, val_acc, per_class_acc, is_best=False):\n",
        "    \"\"\"Save model checkpoint\"\"\"\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'train_accuracy': train_acc,\n",
        "        'val_accuracy': val_acc,\n",
        "        'per_class_accuracy': per_class_acc,\n",
        "        'timestamp': datetime.now().isoformat()\n",
        "    }\n",
        "    \n",
        "    # Save latest checkpoint\n",
        "    torch.save(checkpoint, '/content/efficientnet_latest.pth')\n",
        "    \n",
        "    # Save best checkpoint\n",
        "    if is_best:\n",
        "        torch.save(checkpoint, '/content/efficientnet_best.pth')\n",
        "        print(f\"üíæ New best model saved! Validation accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "print(\"‚úÖ Enhanced training functions defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "main_training"
      },
      "outputs": [],
      "source": [
        "def enhanced_training_pipeline():\n",
        "    \"\"\"Main enhanced training pipeline with all Day 5 optimizations\"\"\"\n",
        "    print(\"üöÄ Starting Enhanced Training Pipeline\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Configuration\n",
        "    config = {\n",
        "        'batch_size': 16,        # Larger batch size for GPU\n",
        "        'base_lr': 0.0005,      # Optimized learning rate from Day 5 analysis\n",
        "        'patience': 10,         # Early stopping patience\n",
        "        'min_delta': 0.001      # Minimum improvement threshold\n",
        "    }\n",
        "    \n",
        "    print(f\"üìã Configuration: {json.dumps(config, indent=2)}\")\n",
        "    \n",
        "    try:\n",
        "        # Create data loaders\n",
        "        train_loader, val_loader, test_loader, train_dataset = create_data_loaders(config['batch_size'])\n",
        "        \n",
        "        # Create enhanced model\n",
        "        model = create_enhanced_model()\n",
        "        \n",
        "        # Setup transfer learning strategy\n",
        "        transfer_strategy = TransferLearningStrategy(model, config['base_lr'])\n",
        "        \n",
        "        # Create loss function with class weights\n",
        "        class_weights = train_dataset.get_class_weights().to(device)\n",
        "        criterion = WeightedFocalLoss(class_weights, alpha=0.25, gamma=2.0)\n",
        "        \n",
        "        # Training history\n",
        "        history = {\n",
        "            'train_loss': [], 'train_acc': [],\n",
        "            'val_loss': [], 'val_acc': [],\n",
        "            'per_class_acc': [],\n",
        "            'stage_transitions': []\n",
        "        }\n",
        "        \n",
        "        best_val_acc = 0.0\n",
        "        patience_counter = 0\n",
        "        global_epoch = 0\n",
        "        \n",
        "        # Multi-stage training\n",
        "        for stage in range(4):  # 4 transfer learning stages\n",
        "            print(f\"\\n{'='*20} STAGE {stage} {'='*20}\")\n",
        "            \n",
        "            # Setup stage\n",
        "            stage_info = transfer_strategy.setup_stage(stage)\n",
        "            optimizer = transfer_strategy.get_optimizer(stage)\n",
        "            \n",
        "            # Learning rate scheduler\n",
        "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                optimizer, mode='min', patience=3, factor=0.5, verbose=True\n",
        "            )\n",
        "            \n",
        "            stage_epochs = stage_info['epochs']\n",
        "            stage_best_acc = 0.0\n",
        "            \n",
        "            # Stage training loop\n",
        "            for epoch in range(stage_epochs):\n",
        "                epoch_start = time.time()\n",
        "                \n",
        "                print(f\"\\nüîÑ Stage {stage}, Epoch {epoch+1}/{stage_epochs} (Global: {global_epoch+1})\")\n",
        "                \n",
        "                # Training\n",
        "                train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, epoch, stage)\n",
        "                \n",
        "                # Validation\n",
        "                val_loss, val_acc, per_class_acc = validate_epoch(model, val_loader, criterion)\n",
        "                \n",
        "                # Update scheduler\n",
        "                scheduler.step(val_loss)\n",
        "                \n",
        "                # Update history\n",
        "                history['train_loss'].append(train_loss)\n",
        "                history['train_acc'].append(train_acc)\n",
        "                history['val_loss'].append(val_loss)\n",
        "                history['val_acc'].append(val_acc)\n",
        "                history['per_class_acc'].append(per_class_acc)\n",
        "                \n",
        "                # Check for best model\n",
        "                is_best = val_acc > best_val_acc\n",
        "                if is_best:\n",
        "                    best_val_acc = val_acc\n",
        "                    stage_best_acc = val_acc\n",
        "                    patience_counter = 0\n",
        "                else:\n",
        "                    patience_counter += 1\n",
        "                \n",
        "                # Save checkpoint\n",
        "                save_checkpoint(model, optimizer, global_epoch, train_acc, val_acc, per_class_acc, is_best)\n",
        "                \n",
        "                # Progress report\n",
        "                epoch_time = time.time() - epoch_start\n",
        "                print(f\"   üìä Train: {train_acc:.1f}% | Val: {val_acc:.1f}% | Best: {best_val_acc:.1f}% [{epoch_time:.1f}s]\")\n",
        "                \n",
        "                # Per-class accuracy\n",
        "                class_acc_str = \" | \".join([f\"{k}: {v:.1f}%\" for k, v in per_class_acc.items()])\n",
        "                print(f\"   üéØ Per-class: {class_acc_str}\")\n",
        "                \n",
        "                global_epoch += 1\n",
        "                \n",
        "                # Early stopping within stage\n",
        "                if patience_counter >= config['patience'] // 2:  # Reduced patience for stages\n",
        "                    print(f\"   ‚èπÔ∏è  Early stopping in stage {stage}\")\n",
        "                    break\n",
        "            \n",
        "            # Record stage transition\n",
        "            history['stage_transitions'].append({\n",
        "                'stage': stage,\n",
        "                'epoch': global_epoch,\n",
        "                'best_acc': stage_best_acc,\n",
        "                'stage_name': stage_info['name']\n",
        "            })\n",
        "            \n",
        "            print(f\"   ‚úÖ Stage {stage} completed. Best: {stage_best_acc:.2f}%\")\n",
        "            \n",
        "            # Check if we should continue\n",
        "            if best_val_acc >= 85.0:  # Target accuracy achieved\n",
        "                print(f\"üéâ Target accuracy (85%) achieved: {best_val_acc:.2f}%\")\n",
        "                break\n",
        "        \n",
        "        total_time = time.time() - start_time\n",
        "        \n",
        "        print(f\"\\nüèÅ Enhanced Training Complete!\")\n",
        "        print(f\"   ‚è±Ô∏è  Total time: {total_time/60:.1f} minutes\")\n",
        "        print(f\"   üéØ Best validation accuracy: {best_val_acc:.2f}%\")\n",
        "        print(f\"   üìä Total epochs: {global_epoch}\")\n",
        "        \n",
        "        # Save training history\n",
        "        with open('/content/training_history.json', 'w') as f:\n",
        "            json.dump(history, f, indent=2)\n",
        "        \n",
        "        print(f\"   üíæ Training history saved to training_history.json\")\n",
        "        \n",
        "        return model, history, best_val_acc\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Training failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, None, 0.0\n",
        "\n",
        "print(\"‚úÖ Enhanced training pipeline ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "execute_section"
      },
      "source": [
        "## üé¨ 6. Execute Training\n",
        "\n",
        "### Run the Complete Enhanced Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "execute_training"
      },
      "outputs": [],
      "source": [
        "# Execute the enhanced training pipeline\n",
        "print(\"üöÄ EXECUTING ENHANCED TRAINING PIPELINE\")\n",
        "print(\"üéØ Target: >85% validation accuracy\")\n",
        "print(\"‚ö° GPU-accelerated with all Day 5 optimizations\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# Run training\n",
        "model, history, best_accuracy = enhanced_training_pipeline()\n",
        "\n",
        "if model is not None:\n",
        "    print(\"\\nüéâ TRAINING SUCCESS!\")\n",
        "    print(f\"   Best validation accuracy: {best_accuracy:.2f}%\")\n",
        "    print(f\"   Target (85%): {'‚úÖ ACHIEVED' if best_accuracy >= 85.0 else '‚ùå NOT ACHIEVED'}\")\nelse:\n",
        "    print(\"\\n‚ùå TRAINING FAILED\")\n",
        "    print(\"   Please check the error messages above\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualization_section"
      },
      "source": [
        "## üìä 7. Training Analysis & Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plot_results"
      },
      "outputs": [],
      "source": [
        "def plot_training_results(history):\n",
        "    \"\"\"Plot comprehensive training results\"\"\"\n",
        "    if not history:\n",
        "        print(\"‚ùå No training history available\")\n",
        "        return\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    \n",
        "    epochs = list(range(len(history['train_acc'])))\n",
        "    \n",
        "    # Training and validation accuracy\n",
        "    axes[0, 0].plot(epochs, history['train_acc'], 'b-', label='Training Accuracy', linewidth=2)\n",
        "    axes[0, 0].plot(epochs, history['val_acc'], 'r-', label='Validation Accuracy', linewidth=2)\n",
        "    axes[0, 0].axhline(y=85, color='g', linestyle='--', label='Target (85%)')\n",
        "    axes[0, 0].set_title('Training Progress: Accuracy', fontsize=14, fontweight='bold')\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Accuracy (%)')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Training and validation loss\n",
        "    axes[0, 1].plot(epochs, history['train_loss'], 'b-', label='Training Loss', linewidth=2)\n",
        "    axes[0, 1].plot(epochs, history['val_loss'], 'r-', label='Validation Loss', linewidth=2)\n",
        "    axes[0, 1].set_title('Training Progress: Loss', fontsize=14, fontweight='bold')\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('Loss')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Per-class accuracy over time\n",
        "    if history['per_class_acc']:\n",
        "        class_names = ['simple', 'text', 'gradient', 'complex']\n",
        "        colors = ['blue', 'orange', 'green', 'red']\n",
        "        \n",
        "        for i, (class_name, color) in enumerate(zip(class_names, colors)):\n",
        "            class_acc = [acc.get(class_name, 0) for acc in history['per_class_acc']]\n",
        "            axes[1, 0].plot(epochs, class_acc, color=color, label=f'{class_name.title()}', linewidth=2)\n",
        "        \n",
        "        axes[1, 0].axhline(y=80, color='gray', linestyle='--', alpha=0.7, label='Target (80%)')\n",
        "        axes[1, 0].set_title('Per-Class Accuracy Progress', fontsize=14, fontweight='bold')\n",
        "        axes[1, 0].set_xlabel('Epoch')\n",
        "        axes[1, 0].set_ylabel('Accuracy (%)')\n",
        "        axes[1, 0].legend()\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Stage transitions\n",
        "    if history['stage_transitions']:\n",
        "        stage_epochs = [t['epoch'] for t in history['stage_transitions']]\n",
        "        stage_accs = [t['best_acc'] for t in history['stage_transitions']]\n",
        "        stage_names = [t['stage_name'] for t in history['stage_transitions']]\n",
        "        \n",
        "        bars = axes[1, 1].bar(range(len(stage_names)), stage_accs, \n",
        "                             color=['lightblue', 'lightgreen', 'lightyellow', 'lightcoral'])\n",
        "        axes[1, 1].axhline(y=85, color='red', linestyle='--', label='Target (85%)')\n",
        "        axes[1, 1].set_title('Best Accuracy by Training Stage', fontsize=14, fontweight='bold')\n",
        "        axes[1, 1].set_xlabel('Training Stage')\n",
        "        axes[1, 1].set_ylabel('Best Accuracy (%)')\n",
        "        axes[1, 1].set_xticks(range(len(stage_names)))\n",
        "        axes[1, 1].set_xticklabels([name.replace('_', '\\n') for name in stage_names], rotation=45)\n",
        "        axes[1, 1].legend()\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Add value labels on bars\n",
        "        for bar, acc in zip(bars, stage_accs):\n",
        "            height = bar.get_height()\n",
        "            axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + 1,\n",
        "                           f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/training_results.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"üìä Training visualization saved as training_results.png\")\n",
        "\n",
        "# Plot results if training was successful\n",
        "if 'history' in locals() and history:\n",
        "    plot_training_results(history)\nelse:\n",
        "    print(\"‚ö†Ô∏è  No training history to plot\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evaluation_section"
      },
      "source": [
        "## üß™ 8. Model Evaluation & Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "final_evaluation"
      },
      "outputs": [],
      "source": [
        "def evaluate_final_model():\n",
        "    \"\"\"Comprehensive evaluation of the trained model\"\"\"\n",
        "    print(\"üß™ Final Model Evaluation\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    try:\n",
        "        # Load best model\n",
        "        if os.path.exists('/content/efficientnet_best.pth'):\n",
        "            checkpoint = torch.load('/content/efficientnet_best.pth', map_location=device)\n",
        "            \n",
        "            # Create model and load weights\n",
        "            eval_model = create_enhanced_model()\n",
        "            eval_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            eval_model.eval()\n",
        "            \n",
        "            print(f\"‚úÖ Best model loaded (Epoch {checkpoint['epoch']})\")\n",
        "            print(f\"   Validation accuracy: {checkpoint['val_accuracy']:.2f}%\")\n",
        "            \n",
        "            # Create test data loader\n",
        "            _, _, test_loader, _ = create_data_loaders(batch_size=16)\n",
        "            \n",
        "            # Evaluate on test set\n",
        "            test_correct = 0\n",
        "            test_total = 0\n",
        "            class_correct = {i: 0 for i in range(4)}\n",
        "            class_total = {i: 0 for i in range(4)}\n",
        "            class_names = ['simple', 'text', 'gradient', 'complex']\n",
        "            \n",
        "            all_predictions = []\n",
        "            all_labels = []\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                for images, labels in test_loader:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    \n",
        "                    outputs = eval_model(images)\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    \n",
        "                    test_total += labels.size(0)\n",
        "                    test_correct += (predicted == labels).sum().item()\n",
        "                    \n",
        "                    # Per-class metrics\n",
        "                    for i in range(len(labels)):\n",
        "                        label = labels[i].item()\n",
        "                        class_total[label] += 1\n",
        "                        if predicted[i].item() == label:\n",
        "                            class_correct[label] += 1\n",
        "                    \n",
        "                    all_predictions.extend(predicted.cpu().numpy())\n",
        "                    all_labels.extend(labels.cpu().numpy())\n",
        "            \n",
        "            test_accuracy = 100. * test_correct / test_total\n",
        "            \n",
        "            print(f\"\\nüìä Test Set Results:\")\n",
        "            print(f\"   Overall accuracy: {test_accuracy:.2f}%\")\n",
        "            print(f\"   Target (85%): {'‚úÖ ACHIEVED' if test_accuracy >= 85.0 else '‚ùå NOT ACHIEVED'}\")\n",
        "            \n",
        "            print(f\"\\nüéØ Per-Class Test Accuracy:\")\n",
        "            for i, class_name in enumerate(class_names):\n",
        "                if class_total[i] > 0:\n",
        "                    class_acc = class_correct[i] / class_total[i] * 100\n",
        "                    status = '‚úÖ' if class_acc >= 80.0 else '‚ùå'\n",
        "                    print(f\"   {class_name.title():8s}: {class_acc:5.1f}% ({class_correct[i]}/{class_total[i]}) {status}\")\n",
        "                else:\n",
        "                    print(f\"   {class_name.title():8s}: No test samples\")\n",
        "            \n",
        "            # Create confusion matrix\n",
        "            from sklearn.metrics import confusion_matrix, classification_report\n",
        "            import seaborn as sns\n",
        "            \n",
        "            cm = confusion_matrix(all_labels, all_predictions)\n",
        "            \n",
        "            plt.figure(figsize=(8, 6))\n",
        "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "                       xticklabels=class_names, yticklabels=class_names)\n",
        "            plt.title('Confusion Matrix - Test Set', fontsize=14, fontweight='bold')\n",
        "            plt.xlabel('Predicted Label')\n",
        "            plt.ylabel('True Label')\n",
        "            plt.tight_layout()\n",
        "            plt.savefig('/content/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "            plt.show()\n",
        "            \n",
        "            # Classification report\n",
        "            print(f\"\\nüìã Detailed Classification Report:\")\n",
        "            report = classification_report(all_labels, all_predictions, \n",
        "                                         target_names=class_names, digits=3)\n",
        "            print(report)\n",
        "            \n",
        "            # Save evaluation results\n",
        "            eval_results = {\n",
        "                'test_accuracy': test_accuracy,\n",
        "                'per_class_accuracy': {\n",
        "                    class_names[i]: (class_correct[i] / class_total[i] * 100 if class_total[i] > 0 else 0)\n",
        "                    for i in range(len(class_names))\n",
        "                },\n",
        "                'confusion_matrix': cm.tolist(),\n",
        "                'classification_report': report,\n",
        "                'model_checkpoint': {\n",
        "                    'epoch': checkpoint['epoch'],\n",
        "                    'val_accuracy': checkpoint['val_accuracy']\n",
        "                }\n",
        "            }\n",
        "            \n",
        "            with open('/content/evaluation_results.json', 'w') as f:\n",
        "                json.dump(eval_results, f, indent=2)\n",
        "            \n",
        "            print(f\"\\nüíæ Evaluation results saved to evaluation_results.json\")\n",
        "            \n",
        "            return test_accuracy\n",
        "            \n",
        "        else:\n",
        "            print(\"‚ùå No trained model found (efficientnet_best.pth)\")\n",
        "            return 0.0\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Evaluation failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return 0.0\n",
        "\n",
        "# Run final evaluation\n",
        "if 'model' in locals() and model is not None:\n",
        "    final_test_accuracy = evaluate_final_model()\nelse:\n",
        "    print(\"‚ö†Ô∏è  No trained model available for evaluation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download_section"
      },
      "source": [
        "## üì• 9. Download Results\n",
        "\n",
        "### Download Trained Model and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_results"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "def create_results_package():\n",
        "    \"\"\"Create a comprehensive results package for download\"\"\"\n",
        "    print(\"üì¶ Creating results package...\")\n",
        "    \n",
        "    # List of files to include\n",
        "    files_to_zip = [\n",
        "        ('/content/efficientnet_best.pth', 'Best trained model'),\n",
        "        ('/content/efficientnet_latest.pth', 'Latest model checkpoint'),\n",
        "        ('/content/training_history.json', 'Training history'),\n",
        "        ('/content/evaluation_results.json', 'Evaluation results'),\n",
        "        ('/content/training_results.png', 'Training plots'),\n",
        "        ('/content/confusion_matrix.png', 'Confusion matrix')\n",
        "    ]\n",
        "    \n",
        "    # Create ZIP file\n",
        "    with zipfile.ZipFile('/content/logo_classification_results.zip', 'w') as zipf:\n",
        "        for file_path, description in files_to_zip:\n",
        "            if os.path.exists(file_path):\n",
        "                zipf.write(file_path, os.path.basename(file_path))\n",
        "                print(f\"   ‚úÖ Added: {description}\")\n",
        "            else:\n",
        "                print(f\"   ‚ö†Ô∏è  Missing: {description}\")\n",
        "    \n",
        "    print(\"\\nüì• Results package ready for download!\")\n",
        "    return '/content/logo_classification_results.zip'\n",
        "\n",
        "# Create and download results\n",
        "if 'model' in locals() and model is not None:\n",
        "    zip_path = create_results_package()\n",
        "    \n",
        "    print(\"\\nüéâ TRAINING COMPLETE - DOWNLOADING RESULTS\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    if 'best_accuracy' in locals():\n",
        "        print(f\"üéØ Best validation accuracy: {best_accuracy:.2f}%\")\n",
        "        print(f\"üìä Target (85%): {'‚úÖ ACHIEVED' if best_accuracy >= 85.0 else '‚ùå NOT ACHIEVED'}\")\n",
        "    \n",
        "    if 'final_test_accuracy' in locals():\n",
        "        print(f\"üß™ Final test accuracy: {final_test_accuracy:.2f}%\")\n",
        "    \n",
        "    print(\"\\nüì• Downloading complete results package...\")\n",
        "    files.download(zip_path)\n",
        "    \n",
        "    print(\"\\n‚úÖ SUCCESS! Your trained logo classification model is ready!\")\n",
        "    print(\"\\nüìã Package contents:\")\n",
        "    print(\"   ‚Ä¢ efficientnet_best.pth - Best trained model\")\n",
        "    print(\"   ‚Ä¢ training_history.json - Complete training metrics\")\n",
        "    print(\"   ‚Ä¢ evaluation_results.json - Test set evaluation\")\n",
        "    print(\"   ‚Ä¢ training_results.png - Training progress plots\")\n",
        "    print(\"   ‚Ä¢ confusion_matrix.png - Model performance visualization\")\n",
        "    \nelse:\n",
        "    print(\"‚ùå No trained model available for download\")\n",
        "    print(\"   Please run the training pipeline first\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary_section"
      },
      "source": [
        "## üìã 10. Training Summary\n",
        "\n",
        "### Day 5 Enhanced Pipeline Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "training_summary"
      },
      "outputs": [],
      "source": [
        "def print_training_summary():\n",
        "    \"\"\"Print comprehensive training summary\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üéØ DAY 5 ENHANCED TRAINING PIPELINE - SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    print(\"\\nüìã IMPLEMENTED OPTIMIZATIONS:\")\n",
        "    optimizations = [\n",
        "        \"‚úÖ Optimized Hyperparameters (LR: 0.0005, batch: 16, dropout: 0.4)\",\n",
        "        \"‚úÖ Logo-Specific Data Augmentation (brand-preserving)\",\n",
        "        \"‚úÖ Weighted Focal Loss (class imbalance + hard examples)\",\n",
        "        \"‚úÖ Progressive Unfreezing (4-stage transfer learning)\",\n",
        "        \"‚úÖ Enhanced Classifier Architecture (256-dim hidden)\",\n",
        "        \"‚úÖ Gradient Clipping (prevents exploding gradients)\",\n",
        "        \"‚úÖ GPU Acceleration (10-100x faster than CPU)\",\n",
        "        \"‚úÖ Real-time Monitoring (live plots + metrics)\",\n",
        "        \"‚úÖ Advanced Checkpointing (best model preservation)\"\n",
        "    ]\n",
        "    \n",
        "    for opt in optimizations:\n",
        "        print(f\"   {opt}\")\n",
        "    \n",
        "    if 'best_accuracy' in locals() and 'final_test_accuracy' in locals():\n",
        "        print(f\"\\nüìä PERFORMANCE RESULTS:\")\n",
        "        print(f\"   üéØ Best Validation Accuracy: {best_accuracy:.2f}%\")\n",
        "        print(f\"   üß™ Final Test Accuracy: {final_test_accuracy:.2f}%\")\n",
        "        print(f\"   üìà Target Achievement (85%): {'‚úÖ SUCCESS' if best_accuracy >= 85.0 else '‚ùå NOT ACHIEVED'}\")\n",
        "        \n",
        "        if best_accuracy >= 85.0:\n",
        "            print(f\"\\nüéâ CONGRATULATIONS!\")\n",
        "            print(f\"   The enhanced pipeline successfully achieved the Day 5 target!\")\n",
        "        else:\n",
        "            print(f\"\\nüí° NEXT STEPS FOR IMPROVEMENT:\")\n",
        "            suggestions = [\n",
        "                \"‚Ä¢ Increase dataset size (currently limited)\",\n",
        "                \"‚Ä¢ Try different model architectures (ResNet, ViT)\",\n",
        "                \"‚Ä¢ Implement advanced augmentation (mixup, cutmix)\",\n",
        "                \"‚Ä¢ Use ensemble methods\",\n",
        "                \"‚Ä¢ Fine-tune class weighting\"\n",
        "            ]\n",
        "            for suggestion in suggestions:\n",
        "                print(f\"   {suggestion}\")\n",
        "    \n",
        "    print(f\"\\nüöÄ DEPLOYMENT READY:\")\n",
        "    print(f\"   ‚Ä¢ Model: EfficientNet-B0 optimized for logo classification\")\n",
        "    print(f\"   ‚Ä¢ Classes: Simple, Text, Gradient, Complex logos\")\n",
        "    print(f\"   ‚Ä¢ Input: 224x224 RGB images\")\n",
        "    print(f\"   ‚Ä¢ Framework: PyTorch with GPU optimization\")\n",
        "    \n",
        "    print(f\"\\nüíæ FILES CREATED:\")\n",
        "    created_files = [\n",
        "        \"‚Ä¢ efficientnet_best.pth - Trained model weights\",\n",
        "        \"‚Ä¢ training_history.json - Complete training metrics\",\n",
        "        \"‚Ä¢ evaluation_results.json - Test set performance\",\n",
        "        \"‚Ä¢ training_results.png - Training visualization\",\n",
        "        \"‚Ä¢ confusion_matrix.png - Performance matrix\"\n",
        "    ]\n",
        "    \n",
        "    for file_desc in created_files:\n",
        "        print(f\"   {file_desc}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚úÖ DAY 5 ENHANCED TRAINING PIPELINE COMPLETE!\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "# Print summary\n",
        "print_training_summary()"
      ]
    }
  ]\n}