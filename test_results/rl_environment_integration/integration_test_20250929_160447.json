{
  "timestamp": 1759187058.836865,
  "test_name": "rl_environment_integration",
  "results": {
    "initialization": {
      "success": true,
      "environments_tested": 3,
      "initialization_times": [
        0.0036110877990722656,
        0.0016210079193115234,
        0.0014379024505615234
      ],
      "details": [
        {
          "image_path": "test-data/circle_00.png",
          "initialization_time": 0.0036110877990722656,
          "action_space_shape": [
            7
          ],
          "observation_space_shape": [
            15
          ],
          "status": "success"
        },
        {
          "image_path": "test-data/text_tech_00.png",
          "initialization_time": 0.0016210079193115234,
          "action_space_shape": [
            7
          ],
          "observation_space_shape": [
            15
          ],
          "status": "success"
        },
        {
          "image_path": "test-data/gradient_radial_00.png",
          "initialization_time": 0.0014379024505615234,
          "action_space_shape": [
            7
          ],
          "observation_space_shape": [
            15
          ],
          "status": "success"
        }
      ],
      "average_initialization_time": 0.002223332722981771
    },
    "episode_execution": {
      "success": true,
      "episodes_completed": 3,
      "total_steps": 30,
      "total_rewards": [
        -1723.5527002639355,
        -1581.8619825994858,
        -724.9402464372637
      ],
      "episode_details": [
        {
          "episode": 0,
          "episode_length": 10,
          "total_reward": -1723.5527002639355,
          "step_rewards": [
            -47.66356497624271,
            -62.819686910595976,
            -81.9253300546189,
            -101.38731534247587,
            -123.92920681588694,
            -147.49199922633795,
            -174.03217484620492,
            -292.3798462972987,
            -327.40039932615497,
            -364.5231764681186
          ],
          "terminated_early": true,
          "final_info": {
            "step": 10,
            "parameters": {
              "color_precision": 5,
              "layer_difference": 12,
              "corner_threshold": 110,
              "length_threshold": 20.0,
              "max_iterations": 5,
              "splice_threshold": 100,
              "path_precision": 15,
              "mode": "spline"
            },
            "quality": 0.16238734153673184,
            "best_quality": 0.16839861222391606,
            "processing_time": 0.009284257888793945,
            "file_size": 0.4541015625,
            "success": true,
            "quality_improvement": -0.33761265846326816,
            "target_reached": false
          }
        },
        {
          "episode": 1,
          "episode_length": 10,
          "total_reward": -1581.8619825994858,
          "step_rewards": [
            -47.03789766917034,
            -62.573297474804264,
            -146.10788245958946,
            -101.0071290708084,
            -124.07581564538522,
            -227.73573292417848,
            -174.73091337350291,
            -202.0099696725946,
            -232.27123599471489,
            -264.31210831473726
          ],
          "terminated_early": true,
          "final_info": {
            "step": 10,
            "parameters": {
              "color_precision": 2,
              "layer_difference": 16,
              "corner_threshold": 10,
              "length_threshold": 20.0,
              "max_iterations": 20,
              "splice_threshold": 100,
              "path_precision": 12,
              "mode": "spline"
            },
            "quality": 0.16238734153673184,
            "best_quality": 0.16670775912690614,
            "processing_time": 0.008675098419189453,
            "file_size": 0.42578125,
            "success": true,
            "quality_improvement": -0.33761265846326816,
            "target_reached": false
          }
        },
        {
          "episode": 2,
          "episode_length": 10,
          "total_reward": -724.9402464372637,
          "step_rewards": [
            -46.059738526899075,
            -62.80832118384769,
            -146.0044580815812,
            -171.33187751938223,
            26.55030849821523,
            12.370057458317607,
            -4.377846045492987,
            -23.39748896288988,
            -44.77812434490367,
            -265.1027577287998
          ],
          "terminated_early": true,
          "final_info": {
            "step": 10,
            "parameters": {
              "color_precision": 10,
              "layer_difference": 10,
              "corner_threshold": 85,
              "length_threshold": 20.0,
              "max_iterations": 20,
              "splice_threshold": 100,
              "path_precision": 19,
              "mode": "spline"
            },
            "quality": 0.16238734153673184,
            "best_quality": 0.16974869389088373,
            "processing_time": 0.011085987091064453,
            "file_size": 0.4931640625,
            "success": true,
            "quality_improvement": -0.33761265846326816,
            "target_reached": false
          }
        }
      ],
      "average_episode_length": 10.0,
      "average_total_reward": -1343.4516431002282
    },
    "reset_consistency": {
      "success": true,
      "reset_tests": 5,
      "consistency_checks": [
        {
          "reset_test": 1,
          "obs_shape_consistent": true,
          "obs_length": 15,
          "info_keys": [
            "episode",
            "step",
            "baseline_quality",
            "current_params"
          ]
        },
        {
          "reset_test": 2,
          "obs_shape_consistent": true,
          "obs_length": 15,
          "info_keys": [
            "episode",
            "step",
            "baseline_quality",
            "current_params"
          ]
        },
        {
          "reset_test": 3,
          "obs_shape_consistent": true,
          "obs_length": 15,
          "info_keys": [
            "episode",
            "step",
            "baseline_quality",
            "current_params"
          ]
        },
        {
          "reset_test": 4,
          "obs_shape_consistent": true,
          "obs_length": 15,
          "info_keys": [
            "episode",
            "step",
            "baseline_quality",
            "current_params"
          ]
        }
      ],
      "details": [
        {
          "reset_test": 0,
          "observation_shape": [
            15
          ],
          "info_keys": [
            "episode",
            "step",
            "baseline_quality",
            "current_params"
          ],
          "status": "success"
        },
        {
          "reset_test": 1,
          "observation_shape": [
            15
          ],
          "info_keys": [
            "episode",
            "step",
            "baseline_quality",
            "current_params"
          ],
          "status": "success"
        },
        {
          "reset_test": 2,
          "observation_shape": [
            15
          ],
          "info_keys": [
            "episode",
            "step",
            "baseline_quality",
            "current_params"
          ],
          "status": "success"
        },
        {
          "reset_test": 3,
          "observation_shape": [
            15
          ],
          "info_keys": [
            "episode",
            "step",
            "baseline_quality",
            "current_params"
          ],
          "status": "success"
        },
        {
          "reset_test": 4,
          "observation_shape": [
            15
          ],
          "info_keys": [
            "episode",
            "step",
            "baseline_quality",
            "current_params"
          ],
          "status": "success"
        }
      ]
    },
    "reward_calculation": {
      "success": true,
      "reward_tests": 3,
      "reward_ranges": [
        550.0,
        -14.850000000000009,
        -5.0
      ],
      "reward_components": [
        {
          "quality_reward": 2.2500000000000004,
          "speed_reward": 0.20000000000000004,
          "size_reward": 0.2,
          "target_bonus": 68.0,
          "convergence_reward": 0.0,
          "failure_penalty": 0.0,
          "step_penalty": -0.2
        },
        {
          "quality_reward": -0.2500000000000002,
          "speed_reward": 0.20000000000000004,
          "size_reward": 0.2,
          "target_bonus": 0.0,
          "convergence_reward": 0.0,
          "failure_penalty": 0.0,
          "step_penalty": -0.2
        },
        {
          "quality_reward": 0.0,
          "speed_reward": 0.0,
          "size_reward": 0.0,
          "target_bonus": 0.0,
          "convergence_reward": 0.0,
          "failure_penalty": -10.0,
          "step_penalty": 0.0
        }
      ],
      "details": [
        {
          "scenario": "quality_improvement",
          "reward": 550.0,
          "components": {
            "quality_reward": 2.2500000000000004,
            "speed_reward": 0.20000000000000004,
            "size_reward": 0.2,
            "target_bonus": 68.0,
            "convergence_reward": 0.0,
            "failure_penalty": 0.0,
            "step_penalty": -0.2
          },
          "expected_positive": true,
          "actual_positive": true,
          "expectation_met": true,
          "status": "success"
        },
        {
          "scenario": "quality_degradation",
          "reward": -14.850000000000009,
          "components": {
            "quality_reward": -0.2500000000000002,
            "speed_reward": 0.20000000000000004,
            "size_reward": 0.2,
            "target_bonus": 0.0,
            "convergence_reward": 0.0,
            "failure_penalty": 0.0,
            "step_penalty": -0.2
          },
          "expected_positive": false,
          "actual_positive": false,
          "expectation_met": true,
          "status": "success"
        },
        {
          "scenario": "conversion_failure",
          "reward": -5.0,
          "components": {
            "quality_reward": 0.0,
            "speed_reward": 0.0,
            "size_reward": 0.0,
            "target_bonus": 0.0,
            "convergence_reward": 0.0,
            "failure_penalty": -10.0,
            "step_penalty": 0.0
          },
          "expected_positive": false,
          "actual_positive": false,
          "expectation_met": true,
          "status": "success"
        }
      ],
      "reward_min": -14.850000000000009,
      "reward_max": 550.0,
      "reward_mean": 176.71666666666667
    },
    "action_mapping": {
      "success": false,
      "mapping_tests": 0,
      "parameter_ranges": {},
      "details": [
        {
          "status": "failed",
          "error": "'VTracerParameterBounds' object has no attribute 'validate_parameters'"
        }
      ]
    }
  },
  "overall_success": false
}