{
  "timestamp": 1759187193.2981498,
  "test_name": "rl_environment_integration",
  "results": {
    "initialization": {
      "success": true,
      "environments_tested": 3,
      "initialization_times": [
        0.0021829605102539062,
        0.0015490055084228516,
        0.001135110855102539
      ],
      "details": [
        {
          "image_path": "test-data/circle_00.png",
          "initialization_time": 0.0021829605102539062,
          "action_space_shape": [
            7
          ],
          "observation_space_shape": [
            15
          ],
          "status": "success"
        },
        {
          "image_path": "test-data/text_tech_00.png",
          "initialization_time": 0.0015490055084228516,
          "action_space_shape": [
            7
          ],
          "observation_space_shape": [
            15
          ],
          "status": "success"
        },
        {
          "image_path": "test-data/gradient_radial_00.png",
          "initialization_time": 0.001135110855102539,
          "action_space_shape": [
            7
          ],
          "observation_space_shape": [
            15
          ],
          "status": "success"
        }
      ],
      "average_initialization_time": 0.0016223589579264324
    },
    "episode_execution": {
      "success": true,
      "episodes_completed": 3,
      "total_steps": 29,
      "total_rewards": [
        -1487.9506716249314,
        -1161.3151402686792,
        -442.34413043343574
      ],
      "episode_details": [
        {
          "episode": 0,
          "episode_length": 10,
          "total_reward": -1487.9506716249314,
          "step_rewards": [
            -47.2486925683295,
            -62.95197102827108,
            49.03191067482384,
            -101.86273412872674,
            -123.7121902765922,
            -147.89223349627227,
            -259.48368181705365,
            -292.9180124974644,
            -233.78599619516456,
            -267.1270702918808
          ],
          "terminated_early": true,
          "final_info": {
            "step": 10,
            "parameters": {
              "color_precision": 10,
              "layer_difference": 14,
              "corner_threshold": 110,
              "length_threshold": 20.0,
              "max_iterations": 5,
              "splice_threshold": 75,
              "path_precision": 20,
              "mode": "spline"
            },
            "quality": 0.1621930985184378,
            "best_quality": 0.16845405840781344,
            "processing_time": 0.01712512969970703,
            "file_size": 0.6474609375,
            "success": true,
            "quality_improvement": -0.3378069014815622,
            "target_reached": false
          }
        },
        {
          "episode": 1,
          "episode_length": 10,
          "total_reward": -1161.3151402686792,
          "step_rewards": [
            -46.74101720669621,
            -62.63568501988111,
            -81.23604525313574,
            -101.21824588071821,
            -123.67995464916214,
            -148.25433650385878,
            -4.755160441651366,
            -202.01953292790466,
            -327.32265627271863,
            -63.4525061129525
          ],
          "terminated_early": true,
          "final_info": {
            "step": 10,
            "parameters": {
              "color_precision": 5,
              "layer_difference": 10,
              "corner_threshold": 93,
              "length_threshold": 11.515559235808158,
              "max_iterations": 20,
              "splice_threshold": 11,
              "path_precision": 9,
              "mode": "spline"
            },
            "quality": 0.1690950678192925,
            "best_quality": 0.1690950678192925,
            "processing_time": 0.009945869445800781,
            "file_size": 1.197265625,
            "success": true,
            "quality_improvement": -0.3309049321807075,
            "target_reached": false
          }
        },
        {
          "episode": 2,
          "episode_length": 9,
          "total_reward": -442.34413043343574,
          "step_rewards": [
            -46.40821605542057,
            -62.64508054060016,
            49.160912929986814,
            39.15705306853472,
            -123.3717658197169,
            -227.66426337298122,
            -5.152783150671821,
            -23.555202852965564,
            -41.86478463960101
          ],
          "terminated_early": true,
          "final_info": {
            "step": 9,
            "parameters": {
              "color_precision": 10,
              "layer_difference": 20,
              "corner_threshold": 110,
              "length_threshold": 6.12530574372534,
              "max_iterations": 20,
              "splice_threshold": 39,
              "path_precision": 2,
              "mode": "spline"
            },
            "quality": 0.16800098747703726,
            "best_quality": 0.16800098747703726,
            "processing_time": 0.013111114501953125,
            "file_size": 0.53515625,
            "success": true,
            "quality_improvement": -0.3319990125229627,
            "target_reached": false
          }
        }
      ],
      "average_episode_length": 9.666666666666666,
      "average_total_reward": -1030.5366474423488
    },
    "reset_consistency": {
      "success": true,
      "reset_tests": 5,
      "consistency_checks": [
        {
          "reset_test": 1,
          "obs_shape_consistent": true,
          "obs_length": 15,
          "info_keys": [
            "episode",
            "step",
            "baseline_quality",
            "current_params"
          ]
        },
        {
          "reset_test": 2,
          "obs_shape_consistent": true,
          "obs_length": 15,
          "info_keys": [
            "episode",
            "step",
            "baseline_quality",
            "current_params"
          ]
        },
        {
          "reset_test": 3,
          "obs_shape_consistent": true,
          "obs_length": 15,
          "info_keys": [
            "episode",
            "step",
            "baseline_quality",
            "current_params"
          ]
        },
        {
          "reset_test": 4,
          "obs_shape_consistent": true,
          "obs_length": 15,
          "info_keys": [
            "episode",
            "step",
            "baseline_quality",
            "current_params"
          ]
        }
      ],
      "details": [
        {
          "reset_test": 0,
          "observation_shape": [
            15
          ],
          "info_keys": [
            "episode",
            "step",
            "baseline_quality",
            "current_params"
          ],
          "status": "success"
        },
        {
          "reset_test": 1,
          "observation_shape": [
            15
          ],
          "info_keys": [
            "episode",
            "step",
            "baseline_quality",
            "current_params"
          ],
          "status": "success"
        },
        {
          "reset_test": 2,
          "observation_shape": [
            15
          ],
          "info_keys": [
            "episode",
            "step",
            "baseline_quality",
            "current_params"
          ],
          "status": "success"
        },
        {
          "reset_test": 3,
          "observation_shape": [
            15
          ],
          "info_keys": [
            "episode",
            "step",
            "baseline_quality",
            "current_params"
          ],
          "status": "success"
        },
        {
          "reset_test": 4,
          "observation_shape": [
            15
          ],
          "info_keys": [
            "episode",
            "step",
            "baseline_quality",
            "current_params"
          ],
          "status": "success"
        }
      ]
    },
    "reward_calculation": {
      "success": true,
      "reward_tests": 3,
      "reward_ranges": [
        550.0,
        -14.850000000000009,
        -5.0
      ],
      "reward_components": [
        {
          "quality_reward": 2.2500000000000004,
          "speed_reward": 0.20000000000000004,
          "size_reward": 0.2,
          "target_bonus": 68.0,
          "convergence_reward": 0.0,
          "failure_penalty": 0.0,
          "step_penalty": -0.2
        },
        {
          "quality_reward": -0.2500000000000002,
          "speed_reward": 0.20000000000000004,
          "size_reward": 0.2,
          "target_bonus": 0.0,
          "convergence_reward": 0.0,
          "failure_penalty": 0.0,
          "step_penalty": -0.2
        },
        {
          "quality_reward": 0.0,
          "speed_reward": 0.0,
          "size_reward": 0.0,
          "target_bonus": 0.0,
          "convergence_reward": 0.0,
          "failure_penalty": -10.0,
          "step_penalty": 0.0
        }
      ],
      "details": [
        {
          "scenario": "quality_improvement",
          "reward": 550.0,
          "components": {
            "quality_reward": 2.2500000000000004,
            "speed_reward": 0.20000000000000004,
            "size_reward": 0.2,
            "target_bonus": 68.0,
            "convergence_reward": 0.0,
            "failure_penalty": 0.0,
            "step_penalty": -0.2
          },
          "expected_positive": true,
          "actual_positive": true,
          "expectation_met": true,
          "status": "success"
        },
        {
          "scenario": "quality_degradation",
          "reward": -14.850000000000009,
          "components": {
            "quality_reward": -0.2500000000000002,
            "speed_reward": 0.20000000000000004,
            "size_reward": 0.2,
            "target_bonus": 0.0,
            "convergence_reward": 0.0,
            "failure_penalty": 0.0,
            "step_penalty": -0.2
          },
          "expected_positive": false,
          "actual_positive": false,
          "expectation_met": true,
          "status": "success"
        },
        {
          "scenario": "conversion_failure",
          "reward": -5.0,
          "components": {
            "quality_reward": 0.0,
            "speed_reward": 0.0,
            "size_reward": 0.0,
            "target_bonus": 0.0,
            "convergence_reward": 0.0,
            "failure_penalty": -10.0,
            "step_penalty": 0.0
          },
          "expected_positive": false,
          "actual_positive": false,
          "expectation_met": true,
          "status": "success"
        }
      ],
      "reward_min": -14.850000000000009,
      "reward_max": 550.0,
      "reward_mean": 176.71666666666667
    },
    "action_mapping": {
      "success": false,
      "mapping_tests": 0,
      "parameter_ranges": {},
      "details": [
        {
          "status": "failed",
          "error": "'bool' object has no attribute 'get'"
        }
      ]
    }
  },
  "overall_success": false
}