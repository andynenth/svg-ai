name: CI/CD Pipeline

on:
  push:
    branches: [ main, master, develop ]
  pull_request:
    branches: [ main, master, develop ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11']

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov flake8 black

    - name: Lint with flake8
      run: |
        # Stop the build if there are Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # Exit-zero treats all errors as warnings
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

    - name: Format check with black
      run: |
        black --check --diff .

    - name: Run tests
      run: |
        pytest tests/ -v --cov=. --cov-report=xml --cov-report=term

    - name: Upload coverage to Codecov
      if: matrix.python-version == '3.9'
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        fail_ci_if_error: false

  benchmark:
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push'

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run benchmarks
      run: |
        python benchmark_suite.py --test-dir data/logos --output-dir benchmark_results

    - name: Upload benchmark results
      uses: actions/upload-artifact@v3
      with:
        name: benchmark-results
        path: benchmark_results/

    - name: Comment PR with results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const results = JSON.parse(fs.readFileSync('benchmark_results/benchmark_report.json', 'utf8'));

          const comment = `## ðŸ“Š Benchmark Results

          | Metric | Value |
          |--------|-------|
          | Avg SSIM | ${results.benchmarks?.single_conversion?.avg_ssim?.toFixed(3) || 'N/A'} |
          | Avg Conversion Time | ${results.benchmarks?.single_conversion?.avg_conversion_time?.toFixed(3) || 'N/A'}s |
          | Detection Speedup | ${results.benchmarks?.detection?.optimized?.speedup?.toFixed(2) || 'N/A'}x |
          | Parallel Speedup (4 workers) | ${results.benchmarks?.parallel?.[4]?.speedup?.toFixed(2) || 'N/A'}x |
          `;

          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });

  quality-check:
    runs-on: ubuntu-latest
    needs: test

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Check conversion quality
      run: |
        # Test on sample logos
        python optimize_iterative.py data/logos/simple_geometric/circle_00.png --target-ssim 0.95
        python optimize_iterative.py data/logos/text_based/text_tech_00.png --target-ssim 0.95

    - name: Generate quality report
      run: |
        python batch_compare.py data/logos/simple_geometric --output comparison_report

    - name: Upload quality report
      uses: actions/upload-artifact@v3
      with:
        name: quality-report
        path: comparison_report/

  deploy:
    runs-on: ubuntu-latest
    needs: [test, benchmark, quality-check]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Build package
      run: |
        python -m pip install --upgrade pip
        pip install build
        python -m build

    - name: Store version
      run: |
        echo "VERSION=$(python -c 'print(__import__("datetime").datetime.now().strftime("%Y.%m.%d"))')" >> $GITHUB_ENV

    - name: Create Release
      if: github.event_name == 'push' && contains(github.event.head_commit.message, '[release]')
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: v${{ env.VERSION }}
        release_name: Release v${{ env.VERSION }}
        body: |
          ## Changes
          ${{ github.event.head_commit.message }}

          ## Performance Metrics
          - Detection Accuracy: 72%
          - Average SSIM: 98%+
          - File Size Reduction: 28% (with post-processing)
        draft: false
        prerelease: false